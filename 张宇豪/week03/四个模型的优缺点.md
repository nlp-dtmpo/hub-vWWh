## 1. BERT (语义表征)

- **优点**：
  - **深度理解上下文**：通过双向注意力机制，能精准识别口语化表达（如“我想听那个谁唱的那个什么歌”）。
  - **精度高**：在情感分析、命名实体识别（NER）等任务上表现极佳。
- **缺点**：
  - **算力成本高**：需要 GPU 才能流畅运行，推理速度比传统方法慢。
  - **延迟挑战**：标准的 BERT 比较重，如果不经过蒸馏（如 TinyBERT, DistilBERT），在 400ms 内完成“语音转文字 + BERT 推理 + 后处理”会有压力。
  - **需要训练数据和高质量标注**：对你产出的“高质量标注数据集”依赖度最高，通常需要数千条标注好的数据进行“微调”才能达到最佳效果。
- **项目适用点**：
  - 是实现 **95% 准确率目标**的核心武器。适合作为 **RESTful API 里的核心分类算法**，处理绝大多数复杂的意图识别。

------

## 2. Prompt (提示词工程)

- **优点**：
  - **零样本/少样本启动**：不需要训练模型，写几句话（提示词）就能让它干活。
  - **逻辑推理最强**：能处理极其模糊的意图，如“帮我看看这车为啥老是提示胎压异常”。
  - **无需微调**：项目初期可以直接通过 Prompt 让大模型辅助生成训练语料（数据增强）。
- **缺点**：
  - **延迟严重超标**：云端大模型响应通常在秒级，**无法满足 400ms** 的实时响应要求。
  - **成本昂贵**：如果每个车载请求都发往 GPT-4 等接口，成本不可控。
- **项目适用点**：
  - 用于**舆情分析**、**非实时意图挖掘**，或者作为**数据标注助手**，在项目中更多扮演的是“**数据分析师**”的角色。

------

## 3. Regex Rule (正则表达式)

- **优点**：
  - **高准确性**：只要模式匹配上了，结果就是确定的，不存在“幻觉”。因此对于固定指令（如“调高温度”、“打开天窗”）百分之百准确，不消耗算力。
  - **速度极快**：毫秒级响应，几乎不占 CPU 资源，处理时间几乎可以忽略不计（<1ms），因此完美满足 400ms 限制。
  - **无需数据**：只要懂规则，写一条就能立刻上线。
- **缺点**：
  - **扩展性差**：语言稍微变一下（比如多了一个错别字），规则就可能失效。比如用户说“我有点冷”或“把冷气关小点”，正则很难覆盖所有表达方式。
  - **维护难**：复杂的正则代码极难调试。20个意图如果全靠正则，规则冲突会导致调试非常难。
- **项目适用点**：
  - 在车载系统中，正则适合作为**“前置过滤”**，来处理**高频、固定格式**的指令，或作为特定词汇（如车型名、地名）的提取工具。

## 4. TF-IDF + ML (传统机器学习)

- **优点**：
  - **解释性强**：可以清晰地看到是因为哪些“高频特征词”导致了分类结果。
  - **训练快**：在普通 CPU 上几秒钟就能训练完成，运行极快，轻松满足 400ms 延迟要求。
  - **样本要求低**：在项目初期数据量不足时，比 BERT 表现更稳健。
- **缺点**：
  - **无语义关联**：它只看词频，不看语序。比如“导航去北京”和“从北京导航出发”，在 TF-IDF 看来特征高度相似，容易误判。
  - **很难达到 95% 的准确率**：面对汽车行业复杂的口语化表达，其上限较低。
- **项目适用点**：
  - 这在项目中常作为**“基准线（Baseline）”**或**“轻量化备选”**。适用于**粗分类**，或者在算力受限的嵌入式端侧设备上运行。