作业2（400字文档， 流程图）: 如何使用bert 进行文本编码，并且使用bert 进行相似度计算，需要写清楚技术方案；
整体流程图：
用户提问
    ↓
【文本预处理】→ 分词、清洗、截断（max_len=128）
    ↓
【BERT编码】 → 加载预训练模型（bert-base-chinese）
    ↓
【CLS向量提取】 → 获取768维句向量
    ↓
【相似度计算】 → 与向量库中所有FAQ向量计算余弦相似度
    ↓
【阈值过滤】 → 最高分 ≥ 0.8：返回对应答案；否则：走兜底/大模型
    ↓
返回回答


主要步骤：
1、离线向量化建库
数据源：从数据库读取所有生效中的FAQ条目，将“标准问题 + 所有相似问法”合并为多个句子。
编码方式：采用Sentence-BERT（SBERT）思路，对每个句子独立编码，取[CLS]向量或对token embeddings进行mean pooling作为句子向量。
存储：向量存入向量数据库，Key为faq_id，Value为向量。

2、在线实时匹配
输入：用户query（如“如何修改密码？”）。
编码：加载BERT模型，tokenize后前向传播，提取句向量。
检索：将句向量与索引库进行近似最近邻检索（ANN），召回Top-K。
后处理：计算精确余弦相似度，取最高分与阈值比较。若最高余弦相似度 ≥ 阈值（如：0.8），返回对应答案；否则转大模型处理或者转人工提示