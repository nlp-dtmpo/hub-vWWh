# 客服 FAQ 语义问答系统设计方案（基于 BERT）

## 作业1：作为后端与算法开发需要做什么

阿里云客服工作台的 FAQ 功能，本质是**结构化知识管理 + 语义匹配问答系统**。页面只是展示层，真正核心在于 FAQ 数据设计、文本向量化、相似度检索以及答案返回。因此，作为后端与算法开发，我们的工作重点并不在页面，而在于知识结构、模型能力和检索能力的建设。

首先，需要设计 FAQ 的**知识结构模型**。BERT 只能处理文本，不能管理知识关系，因此必须通过数据库管理知识结构。至少需要设计以下数据表：

- 一级类目表（category_level1）
- 二级类目表（category_level2）
- FAQ 主表（faq）
- 相似问表（faq_similar_question）

核心思想是：**一个标准问（主问）对应多个相似问和一个标准答案**，并且支持生效时间与类目归属。这样用户用不同表达方式提问时，都可以命中同一个 FAQ。

其次，需要使用**语义模型**而不是关键词匹配。关键词匹配无法理解语义差异，必须使用 BERT 或 Sentence-BERT 将文本转换为向量。向量之间的距离代表语义相似度，从而实现真正的语义检索。

然后，需要实现**相似度检索机制**。所有 FAQ 问题需要预先转为向量并存入向量库（如 Chroma、Milvus 或 Elasticsearch）。当用户提问时，同样转为向量，与向量库进行余弦相似度计算，找到最相似的问题并返回对应答案。

是否需要使用大模型？在该场景下**不需要**。FAQ 属于固定问答场景，而不是开放对话。大模型存在生成不可控、成本高和响应慢的问题。BERT + 向量检索即可满足需求。

因此，后端与算法的主要职责包括：

| 模块 | 职责 |
|---|---|
| 数据库设计 | FAQ 结构、类目、相似问 |
| FAQ 管理接口 | 录入 FAQ、相似问、生效时间 |
| 向量化服务 | 调用 BERT 生成 embedding |
| 向量库存储 | Chroma / Milvus |
| 相似度检索 | TopK 相似问题查找 |
| 答案返回 | 命中 FAQ 直接返回 |

本质上，这是一个**知识管理系统 + 向量检索引擎**。

---

## 作业2：BERT 文本编码与相似度计算技术方案

本方案采用 **Sentence-BERT** 作为文本向量化模型，**ChromaDB** 作为向量数据库，通过**余弦相似度**进行相似问题匹配。Sentence-BERT 专门用于句子相似度计算，比普通 BERT 更适合该场景。

### 技术选型

- 模型：`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- 向量数据库：ChromaDB
- 相似度算法：Cosine Similarity（余弦相似度）

---

### 第一步：FAQ 预处理（离线）

在后台录入 FAQ 和相似问后，使用 Sentence-BERT 将每个问题转换为向量，并存入向量数据库。

示例：

| 文本 | 向量 |
|---|---|
| 怎么提现 | [0.21, -0.33, …] |
| 钱如何取出来 | [0.19, -0.31, …] |

---

### 第二步：用户提问（在线）

当用户输入问题时：

1. 使用 Sentence-BERT 将问题转换为向量
2. 在向量数据库中检索 TopK 相似向量
3. 使用余弦相似度排序
4. 找到最相似的 FAQ
5. 返回对应答案

---

### 相似度计算公式

```
similarity = (A · B) / (|A| * |B|)
```

值越接近 1，表示语义越相似。

---

### 整体流程图

```
管理后台录入FAQ
        │
        ▼
BERT 向量化（离线）
        │
        ▼
存入向量数据库
────────────────────────
        │
用户输入问题
        │
        ▼
BERT 向量化（在线）
        │
        ▼
向量库 TopK 检索
        │
        ▼
余弦相似度排序
        │
        ▼
命中 FAQ → 返回答案
```

---

### 最终效果

无论用户如何表达：

- “钱咋提？”
- “怎么把余额取出来？”
- “提现流程？”

都可以命中同一个 FAQ，并返回准确答案。
